# transformers

Repository for experimentation and learning with the transformer. Includes a pytorch implementation from scratch, as well as some notes on the paper.

# Goal

My goal for this repo is to implement the transformer model from "Attention is All You Need", with only the paper and PyTorch docs as reference. I'll be composing it at the layer level, and not just calling torch.nn.Transformer, obviously.

I'll be implementing a typical text transformer to begin with.

# Stretch Goals

Implement the transformer in other frameworks which I'd like to gain familiarity, ie, Keras. Or in Mojo?
